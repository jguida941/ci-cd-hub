name: unit

on:
  pull_request:
    branches:
      - main
      - master
  push:
    branches:
      - main
      - master
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  pull-requests: write

env:
  PYTHON_VERSION: "3.12"

jobs:
  tests:
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # v4

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          python -m pip install -r requirements-dev.txt

      - name: Run unit tests with coverage
        id: run_tests
        run: |
          set -euo pipefail
          mkdir -p artifacts/unit
          START=$(date +%s)
          TARGETS=(tools/tests)
          if [ -d tests ]; then
            TARGETS+=(tests)
          fi
          pytest \
            --junitxml=artifacts/unit/junit.xml \
            --cov=tools \
            --cov=ingest \
            --cov-report=xml:artifacts/unit/coverage.xml \
            --cov-report=term-missing \
            "${TARGETS[@]}"
          END=$(date +%s)
          DURATION_MS=$(( (END - START) * 1000 ))
          echo "duration_ms=${DURATION_MS}" >> "$GITHUB_OUTPUT"

      - name: Summarize test results
        if: ${{ always() }}
        id: summarize
        run: |
          set -euo pipefail
          python scripts/summarize_junit.py \
            --junit artifacts/unit/junit.xml \
            --output "$GITHUB_OUTPUT"

      - name: Emit pipeline run record
        if: ${{ always() }}
        env:
          TEST_STATUS: ${{ steps.run_tests.outcome }}
          TEST_DURATION_MS: ${{ steps.run_tests.outputs.duration_ms || 0 }}
          TESTS_TOTAL: ${{ steps.summarize.outputs.tests_total || 0 }}
          TESTS_FAILED: ${{ steps.summarize.outputs.tests_failed || 0 }}
          TESTS_SKIPPED: ${{ steps.summarize.outputs.tests_skipped || 0 }}
          TESTS_DURATION_MS: ${{ steps.summarize.outputs.tests_duration_ms || 0 }}
        run: |
          set -euo pipefail
          mkdir -p artifacts
          STATUS="${TEST_STATUS}"
          case "$STATUS" in
            success) STATUS="success" ;;
            failure) STATUS="failed" ;;
            cancelled) STATUS="canceled" ;;
            skipped) STATUS="skipped" ;;
            *) STATUS="failed" ;;
          esac
          python scripts/emit_pipeline_run.py \
            --output artifacts/pipeline_run.ndjson \
            --status "$STATUS" \
            --environment ci \
            --tests-total "${TESTS_TOTAL}" \
            --tests-failed "${TESTS_FAILED}" \
            --tests-skipped "${TESTS_SKIPPED}" \
            --tests-duration-ms "${TESTS_DURATION_MS}" \
            --primary-job-duration-ms "${TEST_DURATION_MS}" \
            --queue-ms 0 \
            --artifact-bytes 0 \
            --runner-os linux \
            --runner-type hosted \
            --region global

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: unit-${{ github.run_id }}
          path: |
            artifacts/unit/junit.xml
            artifacts/unit/coverage.xml
            artifacts/pipeline_run.ndjson
          if-no-files-found: error
